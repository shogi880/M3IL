{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in /storage/home/xin/miniconda3/lib/python3.9/site-packages (8.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/xin/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort\n",
    "import os\n",
    "import shutil\n",
    "from natsort import natsorted\n",
    "import re\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M3IL(ours 70.4%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000, 225000, 250000, 275000, 300000, 325000, 350000, 375000, 400000]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_from_json(file):\n",
    "    try:\n",
    "        with open(file + '/result.json', 'r') as f:\n",
    "            score = json.load(f).get('final_suc')\n",
    "    except:\n",
    "        score = -np.inf\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_from_seed_sentense(seed, sentense_type, text_type='random_instruction'):\n",
    "\n",
    "    experiment_name = f'mill_{text_type}_{seed}_1e-07'\n",
    "    result_path = f'../log_eval/{experiment_name}/eval/first_last_sentence_type_{sentense_type}/random_seed_*'\n",
    "    result_dir = natsorted(glob.glob(result_path))\n",
    "    result_files = natsorted(glob.glob(f'{result_dir[0]}/evaluated_gifs/*'))\n",
    "\n",
    "    test_score = []\n",
    "    train_score = []\n",
    "    for file in result_files:\n",
    "        # print(f\"{file}/result.json\")\n",
    "        if file[-5:] == 'train':\n",
    "            train_score.append(get_score_from_json(file))\n",
    "        else:\n",
    "            test_score.append(get_score_from_json(file))\n",
    "    assert(len(train_score) == len(test_score) == 16)\n",
    "    return train_score, test_score\n",
    "\n",
    "\n",
    "def get_final_score(train_score, test_score):\n",
    "    \n",
    "    # get final score which is the test score at the highest train score.\n",
    "    epochs = [i for i, x in enumerate(train_score) if x == max(train_score)]\n",
    "    \n",
    "    return np.max([test_score[i] for i in epochs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.722972972972973, 0.713963963963964, 0.6779279279279279]\n",
      "mean 0.705 std 0.019\n"
     ]
    }
   ],
   "source": [
    "sentense_type= 'image' # or image\n",
    "# seed= '1' # or image\n",
    "final_score_list = []\n",
    "for seed in [1, 2, 3]:\n",
    "    train_score, test_score = get_scores_from_seed_sentense(seed, sentense_type)\n",
    "    final_score = get_final_score(train_score, test_score)\n",
    "    final_score_list.append(final_score)\n",
    "print(final_score_list)\n",
    "print('mean', np.around(np.mean(final_score_list), 3), 'std', np.around(np.std(final_score_list), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PETNet(67.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from numpyz.\n",
    "def get_data(file):\n",
    "    d = np.load(file, allow_pickle=True)\n",
    "    return pd.DataFrame(d['arr_1'], columns=d['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petnet_image_test_1</th>\n",
       "      <th>petnet_image_train_1</th>\n",
       "      <th>petnet_image_new_test_1</th>\n",
       "      <th>petnet_image_test_3</th>\n",
       "      <th>petnet_image_train_3</th>\n",
       "      <th>petnet_image_new_test_3</th>\n",
       "      <th>petnet_image_test_4</th>\n",
       "      <th>petnet_image_train_4</th>\n",
       "      <th>petnet_image_new_test_4</th>\n",
       "      <th>petnet_image_test_5</th>\n",
       "      <th>...</th>\n",
       "      <th>petnet_image_new_test_5</th>\n",
       "      <th>petnet_image_test_100</th>\n",
       "      <th>petnet_image_train_100</th>\n",
       "      <th>petnet_image_new_test_100</th>\n",
       "      <th>petnet_image_test_200</th>\n",
       "      <th>petnet_image_train_200</th>\n",
       "      <th>petnet_image_new_test_200</th>\n",
       "      <th>petnet_image_test_300</th>\n",
       "      <th>petnet_image_train_300</th>\n",
       "      <th>petnet_image_new_test_300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.423</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.561</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.631</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.599</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       petnet_image_test_1  petnet_image_train_1  petnet_image_new_test_1  \\\n",
       "epoch                                                                       \n",
       "25                   0.243                 0.258                    0.207   \n",
       "50                   0.304                 0.350                    0.252   \n",
       "75                   0.502                 0.542                    0.378   \n",
       "100                  0.475                 0.483                    0.374   \n",
       "125                  0.423                 0.458                    0.313   \n",
       "150                  0.527                 0.608                    0.354   \n",
       "175                  0.561                 0.633                    0.520   \n",
       "200                  0.640                 0.683                    0.495   \n",
       "225                  0.538                 0.617                    0.516   \n",
       "250                  0.660                 0.717                    0.523   \n",
       "275                  0.653                 0.692                    0.545   \n",
       "300                  0.604                 0.683                    0.489   \n",
       "325                  0.631                 0.683                    0.525   \n",
       "350                  0.691                 0.750                    0.514   \n",
       "375                  0.599                 0.700                    0.568   \n",
       "400                  0.626                 0.750                    0.595   \n",
       "\n",
       "       petnet_image_test_3  petnet_image_train_3  petnet_image_new_test_3  \\\n",
       "epoch                                                                       \n",
       "25                   0.255                 0.342                    0.169   \n",
       "50                   0.320                 0.408                    0.245   \n",
       "75                   0.520                 0.500                    0.376   \n",
       "100                  0.468                 0.458                    0.372   \n",
       "125                  0.421                 0.583                    0.347   \n",
       "150                  0.541                 0.533                    0.342   \n",
       "175                  0.536                 0.617                    0.532   \n",
       "200                  0.599                 0.658                    0.507   \n",
       "225                  0.493                 0.583                    0.493   \n",
       "250                  0.633                 0.650                    0.491   \n",
       "275                  0.694                 0.742                    0.563   \n",
       "300                  0.628                 0.667                    0.500   \n",
       "325                  0.651                 0.683                    0.563   \n",
       "350                  0.653                 0.783                    0.538   \n",
       "375                  0.570                 0.692                    0.554   \n",
       "400                  0.655                 0.767                    0.523   \n",
       "\n",
       "       petnet_image_test_4  petnet_image_train_4  petnet_image_new_test_4  \\\n",
       "epoch                                                                       \n",
       "25                   0.273                 0.333                    0.160   \n",
       "50                   0.365                 0.408                    0.223   \n",
       "75                   0.489                 0.525                    0.403   \n",
       "100                  0.484                 0.517                    0.376   \n",
       "125                  0.421                 0.517                    0.302   \n",
       "150                  0.543                 0.533                    0.351   \n",
       "175                  0.550                 0.700                    0.484   \n",
       "200                  0.635                 0.633                    0.466   \n",
       "225                  0.543                 0.558                    0.514   \n",
       "250                  0.617                 0.717                    0.500   \n",
       "275                  0.676                 0.725                    0.568   \n",
       "300                  0.559                 0.700                    0.523   \n",
       "325                  0.644                 0.725                    0.550   \n",
       "350                  0.687                 0.775                    0.561   \n",
       "375                  0.583                 0.725                    0.520   \n",
       "400                  0.664                 0.683                    0.489   \n",
       "\n",
       "       petnet_image_test_5  ...  petnet_image_new_test_5  \\\n",
       "epoch                       ...                            \n",
       "25                   0.257  ...                    0.218   \n",
       "50                   0.288  ...                    0.223   \n",
       "75                   0.473  ...                    0.414   \n",
       "100                  0.500  ...                    0.394   \n",
       "125                  0.412  ...                    0.329   \n",
       "150                  0.543  ...                    0.331   \n",
       "175                  0.536  ...                    0.502   \n",
       "200                  0.626  ...                    0.468   \n",
       "225                  0.493  ...                    0.493   \n",
       "250                  0.635  ...                    0.471   \n",
       "275                  0.705  ...                    0.538   \n",
       "300                  0.599  ...                    0.493   \n",
       "325                  0.669  ...                    0.568   \n",
       "350                  0.678  ...                    0.574   \n",
       "375                  0.597  ...                    0.568   \n",
       "400                  0.644  ...                    0.507   \n",
       "\n",
       "       petnet_image_test_100  petnet_image_train_100  \\\n",
       "epoch                                                  \n",
       "25                     0.243                   0.258   \n",
       "50                     0.304                   0.350   \n",
       "75                     0.502                   0.542   \n",
       "100                    0.475                   0.483   \n",
       "125                    0.423                   0.458   \n",
       "150                    0.527                   0.608   \n",
       "175                    0.561                   0.633   \n",
       "200                    0.640                   0.683   \n",
       "225                    0.538                   0.617   \n",
       "250                    0.660                   0.717   \n",
       "275                    0.653                   0.692   \n",
       "300                    0.604                   0.683   \n",
       "325                    0.631                   0.683   \n",
       "350                    0.691                   0.750   \n",
       "375                    0.599                   0.700   \n",
       "400                    0.626                   0.750   \n",
       "\n",
       "       petnet_image_new_test_100  petnet_image_test_200  \\\n",
       "epoch                                                     \n",
       "25                         0.207                  0.250   \n",
       "50                         0.252                  0.320   \n",
       "75                         0.378                  0.520   \n",
       "100                        0.374                  0.471   \n",
       "125                        0.313                  0.448   \n",
       "150                        0.354                  0.556   \n",
       "175                        0.520                  0.561   \n",
       "200                        0.495                  0.574   \n",
       "225                        0.516                  0.545   \n",
       "250                        0.523                  0.637   \n",
       "275                        0.545                  0.664   \n",
       "300                        0.489                  0.586   \n",
       "325                        0.525                  0.655   \n",
       "350                        0.514                  0.694   \n",
       "375                        0.568                  0.590   \n",
       "400                        0.595                  0.619   \n",
       "\n",
       "       petnet_image_train_200  petnet_image_new_test_200  \\\n",
       "epoch                                                      \n",
       "25                      0.183                      0.227   \n",
       "50                      0.367                      0.205   \n",
       "75                      0.533                      0.417   \n",
       "100                     0.500                      0.354   \n",
       "125                     0.517                      0.293   \n",
       "150                     0.683                      0.394   \n",
       "175                     0.683                      0.550   \n",
       "200                     0.608                      0.464   \n",
       "225                     0.683                      0.525   \n",
       "250                     0.658                      0.525   \n",
       "275                     0.708                      0.586   \n",
       "300                     0.642                      0.545   \n",
       "325                     0.683                      0.581   \n",
       "350                     0.750                      0.570   \n",
       "375                     0.700                      0.590   \n",
       "400                     0.775                      0.511   \n",
       "\n",
       "       petnet_image_test_300  petnet_image_train_300  \\\n",
       "epoch                                                  \n",
       "25                     0.255                   0.342   \n",
       "50                     0.320                   0.408   \n",
       "75                     0.520                   0.500   \n",
       "100                    0.468                   0.458   \n",
       "125                    0.421                   0.583   \n",
       "150                    0.541                   0.533   \n",
       "175                    0.536                   0.617   \n",
       "200                    0.599                   0.658   \n",
       "225                    0.493                   0.583   \n",
       "250                    0.633                   0.650   \n",
       "275                    0.694                   0.742   \n",
       "300                    0.628                   0.667   \n",
       "325                    0.651                   0.683   \n",
       "350                    0.653                   0.783   \n",
       "375                    0.570                   0.692   \n",
       "400                    0.655                   0.767   \n",
       "\n",
       "       petnet_image_new_test_300  \n",
       "epoch                             \n",
       "25                         0.169  \n",
       "50                         0.245  \n",
       "75                         0.376  \n",
       "100                        0.372  \n",
       "125                        0.347  \n",
       "150                        0.342  \n",
       "175                        0.532  \n",
       "200                        0.507  \n",
       "225                        0.493  \n",
       "250                        0.491  \n",
       "275                        0.563  \n",
       "300                        0.500  \n",
       "325                        0.563  \n",
       "350                        0.538  \n",
       "375                        0.554  \n",
       "400                        0.523  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_list = []\n",
    "file = './ex2_numpy/petnet_image.npz'\n",
    "all_result = get_data(file)\n",
    "all_result['epoch'] = [str((i+1) * 25) for i in range(16)]\n",
    "all_result = all_result.set_index('epoch', drop=True).round(3)\n",
    "# all_result.rename(columns=lambda x: x.replace(\"_15types_1_1e-07\", \"\").replace(\"task_id_1\", \"task_id\").replace(\"new_test\", \"newtest\"), inplace=True)\n",
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.691, 0.653, 0.687, 0.678]\n",
      "mean 0.677 std 0.015\n"
     ]
    }
   ],
   "source": [
    "# seed= '1' # or image\n",
    "final_score_list = []\n",
    "seed_list = [1, 3, 4, 5]\n",
    "for seed in seed_list:\n",
    "    train_score = all_result[f'petnet_image_train_{seed}'].values\n",
    "    test_score = all_result[f'petnet_image_test_{seed}'].values\n",
    "    final_score = get_final_score(train_score, test_score)\n",
    "    final_score_list.append(final_score)\n",
    "print(final_score_list)\n",
    "print('mean', np.around(np.mean(final_score_list), 3), 'std', np.around(np.std(final_score_list), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "experiment_name = 'task_id_1'\n",
    "\n",
    "f = f'../experiment1/{experiment_name}/eval/*entence_type_language/random_seed_*'\n",
    "# f = f'../experiment2/{experiment_name}/eval/sentence_type_image/random_seed_*'\n",
    "fs = natsorted(glob.glob(f))\n",
    "print(fs)\n",
    "random_seed = []\n",
    "for i in fs:\n",
    "    random_seed.append(i.split('/')[-1].split('_')[2])\n",
    "# print('experiment_name: ', experiment_name,)\n",
    "random_seed = [1, 2, 3]\n",
    "print('random_seed: ', random_seed)\n",
    "data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "\n",
    "def result_from_folder(experiment_name, random_seed=[1]):\n",
    "    for random in random_seed:    \n",
    "        folder = f'../experiment1/{experiment_name}/eval/*entence_type_language/random_seed_{random}*/evaluated_gifs/*'\n",
    "        files = natsorted(glob.glob(folder))\n",
    "#         print(len(files))\n",
    "        if not files:\n",
    "            print('NO FILES')\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            name = file.split('/')[-1]\n",
    "#             print(name)\n",
    "            epoch = int(re.sub(r'\\D', '', name))\n",
    "            if 'new' in name:\n",
    "                _type = 'new_test'\n",
    "            elif 'train' in name:\n",
    "                _type = 'train'\n",
    "            else:\n",
    "                _type = 'test'\n",
    "#             print(epoch, f'{experiment_name}_{_type}_{random}')\n",
    "#             if random == '1':\n",
    "#                 print(file)\n",
    "            with open(file + '/result.json', 'r') as f:\n",
    "                content = json.load(f)\n",
    "                if content.get('final_suc'):\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('final_suc')\n",
    "                else:\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('new_final_suc')\n",
    "result_from_folder(experiment_name, random_seed)\n",
    "print(data)\n",
    "\n",
    "# output_data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "# for t in ['train', 'test', 'new_test']:  \n",
    "#     list_random = []\n",
    "#     for random in random_seed:\n",
    "#         list_random.append(f'{experiment_name}_{t}_{random}')\n",
    "#     print(list_random)\n",
    "#     output_data[f'{experiment_name}_{t}_mean'] = data[list_random].mean(1)\n",
    "#     output_data[f'{experiment_name}_{t}_std'] = data[list_random].std(1)\n",
    "# output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id_1.npz\n"
     ]
    }
   ],
   "source": [
    "# save to numpyz.\n",
    "name = experiment_name + '.npz'\n",
    "np_data = np.array(data)\n",
    "np_header = np.array(data.columns.tolist())\n",
    "print(name)\n",
    "np.savez(name, np_header, np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bc_language.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3db725707bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load from numpyz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bc_language.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bc_language.npz'"
     ]
    }
   ],
   "source": [
    "# load from numpyz.\n",
    "d = np.load('bc_language.npz', allow_pickle=True)\n",
    "pd.DataFrame(d['arr_1'], columns=d['arr_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Methods & train &  test & new-test \\\\\\hline\\hline\n",
    "\n",
    "PETNet(init image) & 57.8 \\% & 36.4 \\% & 29.3 \\% \\\\\n",
    "MILL(init image) & 55.0 \\% & 43.0 \\% & 37.4 \\% \\\\\n",
    "\\textbf{PETNet(last image)} & \\textbf{83.3} \\% & \\textbf{71.8} \\% & \\textbf{70.0} \\% \\\\\n",
    "MILL(last image) & 80.0 \\% & 65.1 \\% & 63.1 \\% \\\\\\hline\n",
    "PETNet & 73.2\\% & 67.6\\% & 56.2 \\%\\\\\n",
    "MILL & 78.3 \\% & 69.4 \\% & 59.6 \\%\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../experiment2/mill_random_instruction_1_1e-07_last/eval/last_sentence_type_both/random_seed_2_2021-06-15-15-35', '../experiment2/mill_random_instruction_1_1e-07_last/eval/last_sentence_type_both/random_seed_3_2021-06-15-15-35', '../experiment2/mill_random_instruction_1_1e-07_last/eval/sentence_type_both/random_seed_1_2021-06-11-14-00']\n",
      "random_seed:  ['2', '3', '1']\n",
      "        mill_random_instruction_1_1e-07_last_test_2  \\\n",
      "25000                                      0.250000   \n",
      "50000                                      0.288288   \n",
      "75000                                      0.385135   \n",
      "100000                                     0.515766   \n",
      "125000                                     0.581081   \n",
      "150000                                     0.596847   \n",
      "175000                                     0.531532   \n",
      "200000                                     0.650901   \n",
      "225000                                     0.563063   \n",
      "250000                                     0.540541   \n",
      "275000                                     0.603604   \n",
      "300000                                     0.626126   \n",
      "325000                                     0.608108   \n",
      "350000                                     0.567568   \n",
      "375000                                     0.689189   \n",
      "400000                                     0.576577   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_train_2  \\\n",
      "25000                                       0.325000   \n",
      "50000                                       0.291667   \n",
      "75000                                       0.483333   \n",
      "100000                                      0.525000   \n",
      "125000                                      0.583333   \n",
      "150000                                      0.508333   \n",
      "175000                                      0.650000   \n",
      "200000                                      0.691667   \n",
      "225000                                      0.600000   \n",
      "250000                                      0.641667   \n",
      "275000                                      0.725000   \n",
      "300000                                      0.733333   \n",
      "325000                                      0.750000   \n",
      "350000                                      0.658333   \n",
      "375000                                      0.725000   \n",
      "400000                                      0.741667   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_new_test_2  \\\n",
      "25000                                          0.202703   \n",
      "50000                                          0.204955   \n",
      "75000                                          0.310811   \n",
      "100000                                         0.423423   \n",
      "125000                                         0.436937   \n",
      "150000                                         0.515766   \n",
      "175000                                         0.569820   \n",
      "200000                                         0.569820   \n",
      "225000                                         0.536036   \n",
      "250000                                         0.477477   \n",
      "275000                                         0.605856   \n",
      "300000                                         0.558559   \n",
      "325000                                         0.650901   \n",
      "350000                                         0.590090   \n",
      "375000                                         0.578829   \n",
      "400000                                         0.610360   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_test_3  \\\n",
      "25000                                      0.225225   \n",
      "50000                                      0.231982   \n",
      "75000                                      0.403153   \n",
      "100000                                     0.497748   \n",
      "125000                                     0.576577   \n",
      "150000                                     0.560811   \n",
      "175000                                     0.529279   \n",
      "200000                                     0.668919   \n",
      "225000                                     0.551802   \n",
      "250000                                     0.533784   \n",
      "275000                                     0.617117   \n",
      "300000                                     0.635135   \n",
      "325000                                     0.592342   \n",
      "350000                                     0.599099   \n",
      "375000                                     0.603604   \n",
      "400000                                     0.527027   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_train_3  \\\n",
      "25000                                       0.275000   \n",
      "50000                                       0.258333   \n",
      "75000                                       0.466667   \n",
      "100000                                      0.566667   \n",
      "125000                                      0.600000   \n",
      "150000                                      0.625000   \n",
      "175000                                      0.591667   \n",
      "200000                                      0.675000   \n",
      "225000                                      0.683333   \n",
      "250000                                      0.533333   \n",
      "275000                                      0.675000   \n",
      "300000                                      0.733333   \n",
      "325000                                      0.616667   \n",
      "350000                                      0.641667   \n",
      "375000                                      0.641667   \n",
      "400000                                      0.700000   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_new_test_3  \\\n",
      "25000                                          0.173423   \n",
      "50000                                          0.236486   \n",
      "75000                                          0.308559   \n",
      "100000                                         0.394144   \n",
      "125000                                         0.432432   \n",
      "150000                                         0.540541   \n",
      "175000                                         0.500000   \n",
      "200000                                         0.549550   \n",
      "225000                                         0.556306   \n",
      "250000                                         0.493243   \n",
      "275000                                         0.617117   \n",
      "300000                                         0.549550   \n",
      "325000                                         0.596847   \n",
      "350000                                         0.587838   \n",
      "375000                                         0.563063   \n",
      "400000                                         0.623874   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_test_1  \\\n",
      "25000                                      0.238739   \n",
      "50000                                      0.252252   \n",
      "75000                                      0.423423   \n",
      "100000                                     0.556306   \n",
      "125000                                     0.610360   \n",
      "150000                                     0.578829   \n",
      "175000                                     0.545045   \n",
      "200000                                     0.603604   \n",
      "225000                                     0.576577   \n",
      "250000                                     0.545045   \n",
      "275000                                     0.583333   \n",
      "300000                                     0.630631   \n",
      "325000                                     0.650901   \n",
      "350000                                     0.621622   \n",
      "375000                                     0.632883   \n",
      "400000                                     0.522523   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_train_1  \\\n",
      "25000                                       0.225000   \n",
      "50000                                       0.350000   \n",
      "75000                                       0.425000   \n",
      "100000                                      0.533333   \n",
      "125000                                      0.666667   \n",
      "150000                                      0.616667   \n",
      "175000                                      0.575000   \n",
      "200000                                      0.783333   \n",
      "225000                                      0.625000   \n",
      "250000                                      0.608333   \n",
      "275000                                      0.675000   \n",
      "300000                                      0.658333   \n",
      "325000                                      0.733333   \n",
      "350000                                      0.608333   \n",
      "375000                                      0.800000   \n",
      "400000                                      0.683333   \n",
      "\n",
      "        mill_random_instruction_1_1e-07_last_new_test_1  \n",
      "25000                                          0.189189  \n",
      "50000                                          0.261261  \n",
      "75000                                          0.335586  \n",
      "100000                                         0.421171  \n",
      "125000                                         0.466216  \n",
      "150000                                         0.563063  \n",
      "175000                                         0.529279  \n",
      "200000                                         0.574324  \n",
      "225000                                         0.556306  \n",
      "250000                                         0.452703  \n",
      "275000                                         0.603604  \n",
      "300000                                         0.554054  \n",
      "325000                                         0.605856  \n",
      "350000                                         0.630631  \n",
      "375000                                         0.612613  \n",
      "400000                                         0.547297  \n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'mill_random_instruction_1_1e-07_last'\n",
    "\n",
    "f = f'../experiment2/{experiment_name}/eval/*entence_type_both/random_seed_*'\n",
    "# f = f'../experiment2/{experiment_name}/eval/sentence_type_image/random_seed_*'\n",
    "fs = natsorted(glob.glob(f))\n",
    "print(fs)\n",
    "random_seed = []\n",
    "for i in fs:\n",
    "    random_seed.append(i.split('/')[-1].split('_')[2])\n",
    "# print('experiment_name: ', experiment_name,)\n",
    "# random_seed = [1, 2, 3]\n",
    "print('random_seed: ', random_seed)\n",
    "data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "\n",
    "def result_from_folder(experiment_name, random_seed=[1]):\n",
    "    for random in random_seed:    \n",
    "        folder = f'../experiment2/{experiment_name}/eval/*entence_type_both/random_seed_{random}*/evaluated_gifs/*'\n",
    "        files = natsorted(glob.glob(folder))\n",
    "#         print(len(files))\n",
    "        if not files:\n",
    "            print('NO FILES')\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            name = file.split('/')[-1]\n",
    "#             print(name)\n",
    "            epoch = int(re.sub(r'\\D', '', name))\n",
    "            if 'new' in name:\n",
    "                _type = 'new_test'\n",
    "            elif 'train' in name:\n",
    "                _type = 'train'\n",
    "            else:\n",
    "                _type = 'test'\n",
    "#             print(epoch, f'{experiment_name}_{_type}_{random}')\n",
    "#             if random == '1':\n",
    "#                 print(file)\n",
    "            with open(file + '/result.json', 'r') as f:\n",
    "                content = json.load(f)\n",
    "                if content.get('final_suc'):\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('final_suc')\n",
    "                else:\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('new_final_suc')\n",
    "result_from_folder(experiment_name, random_seed)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mill_random_instruction_1_1e-07_last.npz\n"
     ]
    }
   ],
   "source": [
    "# save to numpyz.\n",
    "name = experiment_name + '.npz'\n",
    "np_data = np.array(data)\n",
    "np_header = np.array(data.columns.tolist())\n",
    "print(name)\n",
    "np.savez(name, np_header, np_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instruction_types\n",
    "DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../ablation/1_instruction_types/mill_word_instruction_1_1e-07/eval/first_last_sentence_type_language/random_seed_1_2021-06-15-21-46']\n",
      "random_seed:  [1]\n",
      "        mill_word_instruction_1_1e-07_test_1  \\\n",
      "25000                               0.211712   \n",
      "50000                               0.274775   \n",
      "75000                               0.367117   \n",
      "100000                              0.423423   \n",
      "125000                              0.382883   \n",
      "150000                              0.412162   \n",
      "175000                              0.396396   \n",
      "200000                              0.416667   \n",
      "225000                              0.418919   \n",
      "250000                              0.470721   \n",
      "275000                              0.434685   \n",
      "300000                              0.407658   \n",
      "325000                              0.445946   \n",
      "350000                              0.443694   \n",
      "375000                              0.461712   \n",
      "400000                              0.448198   \n",
      "\n",
      "        mill_word_instruction_1_1e-07_train_1  \\\n",
      "25000                                0.208333   \n",
      "50000                                0.283333   \n",
      "75000                                0.416667   \n",
      "100000                               0.450000   \n",
      "125000                               0.400000   \n",
      "150000                               0.500000   \n",
      "175000                               0.458333   \n",
      "200000                               0.566667   \n",
      "225000                               0.450000   \n",
      "250000                               0.566667   \n",
      "275000                               0.508333   \n",
      "300000                               0.566667   \n",
      "325000                               0.558333   \n",
      "350000                               0.516667   \n",
      "375000                               0.633333   \n",
      "400000                               0.550000   \n",
      "\n",
      "        mill_word_instruction_1_1e-07_new_test_1  \n",
      "25000                                   0.222973  \n",
      "50000                                   0.234234  \n",
      "75000                                   0.351351  \n",
      "100000                                  0.295045  \n",
      "125000                                  0.394144  \n",
      "150000                                  0.400901  \n",
      "175000                                  0.382883  \n",
      "200000                                  0.416667  \n",
      "225000                                  0.403153  \n",
      "250000                                  0.400901  \n",
      "275000                                  0.376126  \n",
      "300000                                  0.457207  \n",
      "325000                                  0.418919  \n",
      "350000                                  0.500000  \n",
      "375000                                  0.486486  \n",
      "400000                                  0.461712  \n"
     ]
    }
   ],
   "source": [
    "# experiment_name = 'mill_random_instruction_1_1e-07_last'\n",
    "experiment_name = 'mill_word_instruction_1_1e-07'\n",
    "sentence_type = 'language'\n",
    "f = f'../ablation/1_instruction_types/{experiment_name}/eval/*entence_type_{sentence_type}/random_seed_*'\n",
    "# f = f'../experiment2/{experiment_name}/eval/sentence_type_image/random_seed_*'\n",
    "fs = natsorted(glob.glob(f))\n",
    "print(fs)\n",
    "random_seed = []\n",
    "for i in fs:\n",
    "    random_seed.append(i.split('/')[-1].split('_')[2])\n",
    "# print('experiment_name: ', experiment_name,)\n",
    "random_seed = [1]\n",
    "print('random_seed: ', random_seed)\n",
    "data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "\n",
    "def result_from_folder(experiment_name, random_seed=[1]):\n",
    "    for random in random_seed:    \n",
    "        folder = f'../ablation/1_instruction_types/{experiment_name}/eval/*entence_type_{sentence_type}/random_seed_{random}_*/evaluated_gifs/*'\n",
    "        files = natsorted(glob.glob(folder))\n",
    "#         print(files)\n",
    "        if not files:\n",
    "            print('NO FILES')\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            name = file.split('/')[-1]\n",
    "#             print(name)\n",
    "            epoch = int(re.sub(r'\\D', '', name))\n",
    "            if 'new' in name:\n",
    "                _type = 'new_test'\n",
    "            elif 'train' in name:\n",
    "                _type = 'train'\n",
    "            else:\n",
    "                _type = 'test'\n",
    "#             print(epoch, f'{experiment_name}_{_type}_{random}')\n",
    "#             if random == '1':\n",
    "#                 print(file)\n",
    "            with open(file + '/result.json', 'r') as f:\n",
    "                content = json.load(f)\n",
    "                if content.get('final_suc'):\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('final_suc')\n",
    "                else:\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('new_final_suc')\n",
    "result_from_folder(experiment_name, random_seed)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mill_word_instruction_1_1e-07_language.npz\n"
     ]
    }
   ],
   "source": [
    "# save to numpyz.\n",
    "name = experiment_name + '_' + sentence_type +'.npz'\n",
    "np_data = np.array(data)\n",
    "np_header = np.array(data.columns.tolist())\n",
    "print(name)\n",
    "np.savez(name, np_header, np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_instruction(15types), sentence_type is Language and Both. seed=1.\n",
    "## training 05, 06, 09, 10.\n",
    "\n",
    "doing: 01, 02, 03, 04 language, 1.both,language.\n",
    "\n",
    "_next: 05, 06, 09, 10. language, both. & 0. 1. ?\n",
    "\n",
    "08. DONE.\n",
    "07. DONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed:  [1]\n",
      "Index(['1_test', '1_train', '1_new_test', '0.01_test', '0.001_test',\n",
      "       '0.0001_test', '0.01_train', '0.001_train', '0.0001_train',\n",
      "       '0.01_new_test', '0.001_new_test', '0.0001_new_test', '0.1_test',\n",
      "       '0.1_train', '0.1_new_test', '1e-05_test', '1e-05_train',\n",
      "       '1e-05_new_test', '1e-06_test', '1e-06_train', '1e-06_new_test',\n",
      "       '1e-07_test', '1e-07_train', '1e-07_new_test', '1e-08_test',\n",
      "       '1e-08_train', '1e-08_new_test', '1e-09_test', '1e-09_train',\n",
      "       '1e-09_new_test', '1e-10_test', '1e-10_train', '1e-10_new_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# experiment_name = 'mill_random_instruction_1_1e-07_last'\n",
    "experiment_name = 'mill_random_instruction_1*'\n",
    "sentence_type = 'both'\n",
    "f = f'../ablation/2_hypa/{experiment_name}/eval/*entence_type_{sentence_type}/random_seed_*/evaluated_gifs/*'\n",
    "fs = natsorted(glob.glob(f))\n",
    "# print(fs)\n",
    "random_seed = []\n",
    "# for i in fs:\n",
    "#     random_seed.append(i.split('/')[-1].split('_')[2])\n",
    "\n",
    "random_seed = [1]\n",
    "print('random_seed: ', random_seed)\n",
    "data = pd.DataFrame(index=[i for i in range(25000, 400001, 25000)])\n",
    "\n",
    "_f = f'../ablation/2_hypa/{experiment_name}/eval/*entence_type_{sentence_type}/random_seed_*/evaluated_gifs/*'\n",
    "_fs = natsorted(glob.glob(_f))\n",
    "# print(_fs)\n",
    "for file in fs:\n",
    "    name = file.split('/')[-1]\n",
    "    experiment_name = file.split('/')[3].split('_')[-1]\n",
    "    epoch = int(re.sub(r'\\D', '', name))\n",
    "    if 'new' in name:\n",
    "        _type = 'new_test'\n",
    "    elif 'train' in name:\n",
    "        _type = 'train'\n",
    "    else:\n",
    "        _type = 'test'\n",
    "    with open(file + '/result.json', 'r') as f:\n",
    "        content = json.load(f)\n",
    "        if content.get('final_suc'):\n",
    "            data.loc[epoch, f'{experiment_name}_{_type}'] = content.get('final_suc')\n",
    "        else:\n",
    "            data.loc[epoch, f'{experiment_name}_{_type}'] = content.get('new_final_suc')\n",
    "#     print(file)\n",
    "#     print(experiment_name)\n",
    "    \n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mill_hypa_both.npz\n"
     ]
    }
   ],
   "source": [
    "# save to numpyz.\n",
    "name = 'mill_hypa_both.npz'\n",
    "np_data = np.array(data)\n",
    "np_header = np.array(data.columns.tolist())\n",
    "print(name)\n",
    "np.savez(name, np_header, np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO FILES\n",
      "          1_test  0.01_test  0.001_test  0.0001_test  0.1_test  1e-05_test  \\\n",
      "25000   0.171171   0.166667    0.313063     0.299550  0.184685    0.144144   \n",
      "50000   0.180180   0.231982    0.218468     0.283784  0.295045    0.292793   \n",
      "75000   0.310811   0.234234    0.250000     0.231982  0.391892    0.245495   \n",
      "100000  0.340090   0.308559    0.340090     0.337838  0.304054    0.261261   \n",
      "125000  0.306306   0.306306    0.195946     0.270270  0.283784    0.301802   \n",
      "150000  0.281532   0.333333    0.299550     0.376126  0.324324    0.319820   \n",
      "175000  0.324324   0.349099    0.268018     0.360360  0.351351    0.286036   \n",
      "200000  0.353604   0.337838    0.364865     0.373874  0.299550    0.313063   \n",
      "225000  0.315315   0.315315    0.319820     0.369369  0.340090    0.295045   \n",
      "250000  0.326577   0.380631    0.340090     0.317568  0.353604    0.355856   \n",
      "275000  0.362613   0.344595    0.394144     0.414414  0.382883    0.301802   \n",
      "300000  0.391892   0.364865    0.331081     0.319820  0.319820    0.371622   \n",
      "325000  0.432432   0.310811    0.346847     0.416667  0.414414    0.369369   \n",
      "350000  0.421171   0.344595    0.353604     0.324324  0.353604    0.340090   \n",
      "375000  0.371622   0.407658    0.364865     0.369369  0.367117    0.400901   \n",
      "400000  0.364865   0.337838    0.416667     0.403153  0.313063    0.344595   \n",
      "\n",
      "        1e-06_test  1e-07_test  1e-08_test  1e-09_test  1e-10_test  \n",
      "25000     0.202703    0.272523    0.193694    0.207207    0.286036  \n",
      "50000     0.423423    0.472973    0.277027    0.211712    0.231982  \n",
      "75000     0.463964    0.500000    0.506757    0.238739    0.265766  \n",
      "100000    0.513514    0.617117    0.502252    0.256757    0.209459  \n",
      "125000    0.540541    0.567568    0.509009    0.189189    0.225225  \n",
      "150000    0.481982    0.659910    0.427928    0.207207    0.371622  \n",
      "175000    0.522523    0.623874    0.601351    0.299550    0.340090  \n",
      "200000    0.574324    0.664414    0.554054    0.182432    0.425676  \n",
      "225000    0.578829    0.662162    0.632883    0.290541    0.412162  \n",
      "250000    0.594595    0.583333    0.648649    0.240991    0.457207  \n",
      "275000    0.599099    0.601351    0.572072    0.254505    0.486486  \n",
      "300000    0.540541    0.738739    0.565315    0.254505    0.432432  \n",
      "325000    0.619369    0.684685    0.608108    0.326577    0.513514  \n",
      "350000    0.628378    0.700450    0.630631    0.351351    0.466216  \n",
      "375000    0.635135    0.731982    0.594595    0.364865    0.445946  \n",
      "400000    0.554054    0.713964    0.545045    0.331081    0.529279  \n"
     ]
    }
   ],
   "source": [
    "def result_from_folder(experiment_name, random_seed=[1]):\n",
    "    for random in random_seed:    \n",
    "        folder = f'../ablation/2_hypa/{experiment_name}/eval/*entence_type_{sentence_type}/random_seed_*/evaluated_gifs/*'\n",
    "        files = natsorted(glob.glob(folder))\n",
    "#         print(files)\n",
    "        if not files:\n",
    "            print('NO FILES')\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            name = file.split('/')[-1]\n",
    "#             print(name)\n",
    "            epoch = int(re.sub(r'\\D', '', name))\n",
    "            if 'new' in name:\n",
    "                _type = 'new_test'\n",
    "            elif 'train' in name:\n",
    "                _type = 'train'\n",
    "            else:\n",
    "                _type = 'test'\n",
    "#             print(epoch, f'{experiment_name}_{_type}_{random}')\n",
    "#             if random == '1':\n",
    "#                 print(file)\n",
    "            with open(file + '/result.json', 'r') as f:\n",
    "                content = json.load(f)\n",
    "                if content.get('final_suc'):\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('final_suc')\n",
    "                else:\n",
    "                    data.loc[epoch, f'{experiment_name}_{_type}_{random}'] = content.get('new_final_suc')\n",
    "result_from_folder(experiment_name, random_seed)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c59143dddf9bb7cb19cf5c4e65abac3edd3adb579b9c354e95a8774ecff661b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
